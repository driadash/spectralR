---
title: "spectralR: Spectral reflectance visualisations for user-defined areas"
author: "Oleh Prylutskyi"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{spectralR: Spectral reflectance visualisations for user-defined areas}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Vignettes are long form documentation commonly included in packages. Because they are part of the distribution of the package, they need to be as compact as possible. The `html_vignette` output type provides a custom style sheet (and tweaks some options) to ensure that the resulting html is as small as possible. The `html_vignette` format:

- Never uses retina figures
- Has a smaller default figure size
- Uses a custom CSS stylesheet instead of the default Twitter Bootstrap style

## Vignette Info

Note the various macros within the `vignette` section of the metadata block above. These are required in order to instruct R how to build the vignette. Note that you should change the `title` field and the `\VignetteIndexEntry` to match the title of your vignette.

## Styles

The `html_vignette` template includes a basic CSS theme. To override this theme you can specify your own CSS in the document metadata as follows:

    output: 
      rmarkdown::html_vignette:
        css: mystyles.css

## Figures

The figure sizes have been customised so that you can easily put two images side-by-side. 

```{r, fig.show='hold'}
plot(1:10)
plot(10:1)
```

You can enable figure captions by `fig_caption: yes` in YAML:

    output:
      rmarkdown::html_vignette:
        fig_caption: yes

Then you can use the chunk option `fig.cap = "Your figure caption."` in **knitr**.

## More Examples

You can write math expressions, e.g. $Y = X\beta + \epsilon$, footnotes^[A footnote here.], and tables, e.g. using `knitr::kable()`.

```{r, echo=FALSE, results='asis'}
knitr::kable(head(mtcars, 10))
```

Also a quote using `>`:

> "He who gives up [code] safety for [code] speed deserves neither."
([via](https://twitter.com/hadleywickham/status/504368538874703872))

## Introduction

`spectralR` is aimed to obtain, process, and visualize spectral reflectance data for the user-defined earth surface classes (it might be different habitat or vegetation types, crops, land uses, landscapes, of any other types of territories or water areas), for visual exploring in which wavelengths the classes differ. Input should be a shapefile with polygons of surface classes (it might be different habitat types, crops, any other things). The single source of spectral data are [Sentinel 2 Level 2A](https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-2) satellite mission optical bands pixel data so far, obtained through [Google Earth Engine](https://earthengine.google.com/) service.

The workflow depends on [rgee](https://r-spatial.github.io/rgee/) R package, which provides a bridge between R and Python API for Google Earth Engine. All the operations with satellite imageries run in a cloud, and afterwards obtained pixel data visualize locally. Therefore, despite of extent of input data, the most resource hungry operations do not overload your local machine. But that means that you need a stable Internet connection for using API.

For using `rgee` you should have a Google Earth Engine account. If you don't, first [register](https://earthengine.google.com/new_signup/) using your Google account.

Depends on operating system you use and your current Python configuration, it may require some additional R and Python packages for running `rgee`. See the following links for instructions. See also [Quick Start User's Guide](https://www.rdocumentation.org/packages/rgee/versions/1.0.7), [Official documentation](https://r-spatial.github.io/rgee/index.html), and the [source code](https://github.com/r-spatial/rgee) of rgee for solving issues arises during installation and setting up.

We strongly encourage you to follow official `rgee` installation guide and messages arrived during installation process.

The overall workflow is following:
1. Load user's ESRI shapefile containing polygons for user-defined surface classes,
as well as the text or numerical field with classes names (labels).
2. Apply `rgee` functionality to retrieve multi-band pixel data for classes polygons from 
Google Earth Engine service.
3. Visualize retrieved pixel data locally, using `ggplot2` approach.

Essential requirements:
- stable Internet connection (for using API)
- Installed and correctly pre-configured Python environment (v. 3.5 or above)
- active Google Earth Engine account

## Essential preparations. Install and set up `rgee`
```{r, eval = FALSE}
remotes::install_github("r-spatial/rgee")
```

Load the library
```{r}
library(rgee)
```

It is necessary just once to complete installation necessary dependencies
```{r, eval = FALSE}
ee_install()
```

If something went wrong in this step, see https://r-spatial.github.io/rgee/index.html#installation

Check non-R dependencies
```{r, eval = FALSE}
ee_check() 
```

`rgee` developers recommend installing the version of the Earth Engine Python API which `rgee` was tested with, using the following command. Despite it calls "upgrade", it might actually downgrade your version of `earthengine_api`.
```{r, eval = FALSE}
ee_install_upgrade()
```

Initialize Google Earth Engine API for current session.
```{r}
ee_Initialize()
```

On this or one of previous step you would be prompted to link your Google earth Engine account with `rgee`. Follow instructions in R console, and you will be re-directered to web browser for logging into your Google Earth Engine account and confirm access rights. An authorization code generated during this step should be pasted into R console to finalize authentification.

If everything is OK on the last step and you see a message of successful initiation of API with your GEE username in console, - congratulations, you managed to install and configure `rgee`!

Pay attention, that `rgee` uses earthengine_api package, which depends on Python. That's why we need to setting up local Python environment for using `rgee`.

Unfortunately, you have to repeat environment setting and re-authorization each time Python gets updates. For actively updated operating systems, like regular versions of Ubuntu, that's quite annoying. On the other hand, this built-in repairing system protects you from accidentally breaking earthengine Python environment during installation or using any other Python-related tools, which is convenient at least if you are such a weak Python user as me. If you get an error message "The current Python PATH: /home/user/.virtualenvs/rgee/bin/python does not have the Python package "earthengine-api" installed. Are you restarted/terminated your R session after install miniconda or run ee_install()?", then proceed instruction appeared in R console, which will help you to delete your previous configuration and set up it again.

--------------------------------------------------------

We offer two use-cases for getting users familiar with the functionality of spectralR. First one is a small-size area in Kharkiv region, Ukraine, where National Park "Homilsha Forests" are situated. The second is the ... hand-drawing polygons of ... different habitat types (according to EUNIS classification system) of Buzky Gard National Park, Mykolaiv region, Ukraine. End users don't expect to notice a large differences in workflow, but under the hood we implemented two different algorithms for either "small" or "large" spatial data, which will be explained later.

## Use case 1. Basic habitat types of 'Homilsha Forests' National Park and neighborhoods.

### Environment preparation
```{r}
# Reset R's brain before new analysis session started. It will erase all the objects stored in 
# R memory, while keep loaded libraries.
rm(list = ls())

# Load required packages
library(tidyverse)
library(rgee)
library(sf)
library(geojsonio)
library(reshape2)
```

Initialize Google Earth Engine API for current session
```{r}
ee_Initialize()
```

### Upload and process vector data

Prepare vector data for further reflectance data sampling.
Function `prepare.vector.data`  takes shapefile with polygons of different classes of surface (habitats, crops, vegetation, etc.), and retrieves ready-for-sampling sf object. One should specify shapefile name (should be within working directory, using absolute paths were not tested), as well as the name of the field which contains class labels. The function extract geometries of all polygons, and marked them by custom labels ('label') and integer class ID ('class'). The last variable is required because Google Earth Engine sampler respects only numerical class ID - don't delete any field!  don't panic: resulting dataframe will be marked according to your custom labels, not hard-to-memorizable numbers.

While preparing a shapefile with custom polygons (e.d., in [QGIS](https://qgis.org/en/site/)), try to follow recommendation:
- if possible, draw polygons in homogeneous landscapes, avoid class mixture;
- tiny polygons (same size as satellite imagery resolution or lesser) resulted in stronger "edge effect";
- few big polygons easier to process than a lot of small ones;
- GEE has its own limitation, which may result in extended processing time

```{r}
# Extract polygons from shapefile and prepare sf object with proper structure
sf_df <- prepare.vector.data("test_shapefile.shp", "veget_type")

# Explore resulting spatial object 
head(df_df)
```

### Obtain pixel values from Sentinel 2A image collection

Function `get.pixel.data` is a heart of `spectralR`. It takes sf polygon object, obtained in the previous step, and retrieves data frame with brightness values for each pixel intersected with polygons, for each optical band of Sentinel-2 sensor, marked according to the label of surface class from the polygons. `get.pixel.data` firstly converts sf object into GEE feature collection, then prepares satellite image for pixel sampling and performs sampling, and finally exports resulting object back into an R dataframe (non-spatial now).

One of the most tricky and issues-causing step of this procedure is convertation beetween R's sf object and GEE's feature collection. `rgee` implements three way to do so:
- through the JSON translator (`getInfo`, default)
- using Google Drive (`getInfo_to_asset`)
- using Google Cloud Storage (`gcs_to_asset`)

First one is the most straightforward and quick, but usable only for small data (less than 15000 entries, or 1.5 MB local files). The other two require mediating storage to store your data between convertations (because Earth Engine is Google service and seamlessly integrated with plenty of Google services).

In `spectralR`, we use first two. `get.pixel.data` assesses the size of your either sf object or feature collection, then activates either `getInfo` or `getInfo_to_asset` pathway. If you data is considered small, you will notice nothing special. But, if your data is larger than our arbitrary threshold, you may be prompted to authorize in Google Drive and allow `rgee` to access GDrive files and folders. In such a case, please follow instructions in the R console and then in your web-browser. You may do it once you perform your first large query, - you credits will be stored into your local earthengine environment.


To use `get.pixel.data`, we need to specify some values:
- polygons of surface classes as a sf object, prepared on previous step;
- starting day for Sentinel image collection, as "YYYY-MM-DD". See Note 1 below;
- final day for Sentinel image collection, as "YYYY-MM-DD";
- cloud threshold (maximum per cent of cloud-covered pixels per image) by which individual 
satellite imageries will be filtered;
- scale of resulting satellite images in meters (pixel size). See Note 2 below;

Resulting pixel data will be saved within working directory and can be loaded during
next sessions.

Note 1.
Particular satellite imagery is typically not ready for instant sampling - it contains clouds, cloud shadows, aerosols, as well as may cover not all the territory you of your interest. Another issue is that each particular pixel slightly differs in reflectance between images taken in different days due to difference in atmospheric conditions and angle of sunlight at the moments images were taken. Google Earth Engine has its own build-in algorithms for image pre-processing, atmospheric corrections and mosaicing, which allows to obtain a ready-to-use, rectified image. Approach used in this script is that to find a median value for each pixel between several images within each of 10 optical band, and thereby make a composite image. To define a set of imageries between which we are going to calculate median, 
we should set a timespan of image collection. Sentinel-2 apparatus takes picture once a 5 days, so if you set up month-long timesnap, you can expect that each pixel value will be calculated based on 5 to 6 values (remember, some images might appear unsatisfactory cloudy).

Note 2.
Finest resolution for Sentinel data - 10 m, while using larger scale values decreases required computational resources and size of resulting dataframe. Although sampling satellite data performs in a cloud, there are some limitations for geocalculatons placed by GEE itself. If you are about to sample large areas, consider setting higher 'scale' value (100, 1000). Read more in GEE [best practices](https://developers.google.com/earth-engine/guides/best_practices).

```{r}
# Get pixel data
reflectance = get.pixel.data(sf_df, "2019-05-15", "2019-06-30", 10, 100)

# Save pixel data for further sessions
save(reflectance, file = "reflectance_data")
```

Let's have a look at the resulting data:
```{r}
head(reflectance)
```

We have a dataframe which number of rows equal to the number of sampled "pixels" of satellite image, as well as 10 variables with reflectance values for each of optical band of Sentinel 2. Each sampled pixel has a label of surface class of user's polygon it intersected.

### Making spectral reflectance curves

First of all, one should explore the quality and comprehensiveness of obtained pixel data.
```{r}
load(file = "./reflectance_data") # restore previously saved pixel data

summary(factor(reflectance$label)) # how many pixels in each class? 
```

For reliable results, it is recommended to keep similar size of each surface class. Classes which represented by few sampled pixels, should be excluded from the further analysis.

Visual overview of pixel data
```{r}
# Number of spectral values for different classes
ggplot(reflectance, aes(x=label))+
  geom_bar()+
  labs(x = 'Classes of surface', y = 'Number of pixels',
       title = "Total pixel data for different classes of surface",
       caption = 'Data: Sentinel-2 Level-2A')+
  theme_minimal()
```

Function `spectral.reflectance.curve` transform the data and plot smoother curves for each surface class, using `ggplot2`'s `geom_smooth()` aesthetics. For large (thousands of rows) data (and we need large data for reliable conclusions!), `ggplot2` uses *GAM* method for drawing a trendline.

Depending on the data size, 
```{r}
p1 <- spectral.curves.plot(reflectance)

p1
```

```{r}
p1+
  labs(x = 'Wavelength, nm', y = 'Reflectance',
       colour = "Surface classes",
       fill = "Surface classes",
       title = "Spectral reflectance curves for different classes of surface",
       caption = 'Data: Sentinel-2 Level-2A')+
  theme_minimal()
```




