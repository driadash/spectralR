---
title: "spectralR: Spectral reflectance visualisations for user-defined areas"
author: "Oleh Prylutskyi"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{spectralR: Spectral reflectance visualisations for user-defined areas}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

`spectralR` [homepage and source code](https://github.com/olehprylutskyi/spectralR) is aimed to obtain, process, and visualize spectral reflectance data for the user-defined earth surface classes (it might be different habitat or vegetation types, crops, land uses, landscapes, of any other types of territories or water areas), for visual exploring in which wavelengths the classes differ. Input should be a shapefile with polygons of surface classes (it might be different habitat types, crops, any other things). The single source of spectral data are [Sentinel 2 Level 2A](https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-2) satellite mission optical bands pixel data so far, obtained through [Google Earth Engine](https://earthengine.google.com/) service.

Initial purpose of `spectralR` development was to quickly explore visually the differences in spectral reflectance patterns for supervised vegetation (and, widely, habitat) mapping. While machine learning classification methods, such as [RandomForests](https://en.wikipedia.org/wiki/Random_forest), typically utilize the full set of available spectral data (satellite bands), we observed that highly similar habitat types (e.g. different types of grasslands, floodplain habitats) may have similar reflectance values during one season and different for another, so time-series reflectance data are also needed. Without the preliminary selection of the most discriminating satellite bands for given habitat types in given conditions, the models became overfitted and required extensive machine resources for calculation.

The [first version](https://github.com/olehprylutskyi/habitat-spectral-reflectance) of our product was a three different codes, two written for R (shapefile preparation and visualization of the results) and one for Google Earth Engine, for satellite image preparation and spectral data sampling itself. That approach, though, required a bunch of manual operations, as well as downloading big files on a local machine. So we moved to the recent [rgee](https://r-spatial.github.io/rgee/) R package, which provides a bridge between R and Python API for Google Earth Engine. All the operations with satellite images now run in a cloud, and afterwards obtained pixel data visualize locally. Therefore, despite of extent of input data, the most resource hungry operations do not overload your local machine. But that means that you need a stable Internet connection for using API.

For using `rgee` you should have a Google Earth Engine account. If you don't, first [register](https://earthengine.google.com/new_signup/) using your Google account.

Depends on operating system you use and your current Python configuration, it may require some additional R and Python packages for running `rgee`. See the following links for instructions. See also [Quick Start User's Guide](https://www.rdocumentation.org/packages/rgee/versions/1.0.7), [Official documentation](https://r-spatial.github.io/rgee/index.html), and the [source code](https://github.com/r-spatial/rgee) of rgee for solving issues arises during installation and setting up.

We strongly encourage you to follow official `rgee` installation guide and messages arrived during installation process.

The overall workflow is following:

1. Load user's ESRI shapefile containing polygons for user-defined surface classes,
as well as the text or numerical field with classes names (labels).
2. Apply `rgee` functionality to retrieve multi-band pixel data for classes polygons from 
Google Earth Engine service.
3. Visualize retrieved pixel data locally, using `ggplot2` approach.

Essential requirements:

* stable Internet connection (for using API)

* Installed and correctly pre-configured Python environment (v. 3.5 or above)

* active Google Earth Engine account


## Essential preparations

### Install and set up `rgee`
```{r, eval = FALSE}
remotes::install_github("r-spatial/rgee")
```

Load the library
```{r}
library(rgee)
```

It is necessary just once to complete installation necessary dependencies
```{r, eval = FALSE}
ee_install()
```

If something went wrong in this step, see `rgee`'s [installation guide](https://r-spatial.github.io/rgee/index.html#installation)

Check non-R dependencies
```{r, eval = FALSE}
ee_check() 
```

`rgee` developers recommend installing the version of the Earth Engine Python API which `rgee` was tested with, using the following command. Despite it calls "upgrade", it might actually downgrade your version of `earthengine_api`.
```{r, eval = FALSE}
ee_install_upgrade()
```

Initialize Google Earth Engine API for current session.
```{r, eval = FALSE}
ee_Initialize()
```

On this or one of previous step you would be prompted to link your Google earth Engine account with `rgee`. Follow instructions in R console, and you will be re-directered to web browser for logging into your Google Earth Engine account and confirm access rights. An authorization code generated during this step should be pasted into R console to finalize authentification.

If everything is OK on the last step and you see a message of successful initiation of API with your GEE username in console, - congratulations, you managed to install and configure `rgee`!

Pay attention, that `rgee` uses earthengine_api package, which depends on Python. That's why we need to setting up local Python environment for using `rgee`.

Unfortunately, you have to repeat environment setting and re-authorization each time Python gets updates. For actively updated operating systems, like regular versions of Ubuntu, that's quite annoying. On the other hand, this built-in repairing system protects you from accidentally breaking earthengine Python environment during installation or using any other Python-related tools, which is convenient at least if you are such a weak Python user as me. If you get an error message 

> "The current Python PATH: /home/user/.virtualenvs/rgee/bin/python does not have the Python package "earthengine-api" installed. Are you restarted/terminated your R session after install miniconda or run ee_install()?"

then proceed instruction appeared in R console, which will help you to delete your previous configuration and set up it again.

### Installation of the other dependencies

```{r, eval = FALSE}
install.packages("geojsonio")
```

### Installation of spectralR

`spectralR` can be installed from **GitHub** sources so far, although we are planning to land it on CRAN soon.
```{r, eval = FALSE}
library(remotes)
install_github("olehprylutskyi/spectralR")
```

--------------------------------------------------------

We offer two use-cases for getting users familiar with the functionality of spectralR. First one is a small-size area in Kharkiv region, Ukraine, where National Park "Homilsha Forests" are situated, with 8 polygons for 5 land use classes -- let's call it "small data". The second - a "large data" - is the 380 hand-drawing polygons of 26 different habitat types (according to EUNIS classification system) of Buzky Gard National Park, Mykolaiv region, Ukraine. End users don't expect to notice a large differences in workflow, but under the hood we implemented two different algorithms for either "small" or "large" spatial data, which will be explained later.

## Use case 1. Basic habitat types of 'Homilsha Forests' National Park and neighborhoods.

### Environment preparation
```{r, error=FALSE, warning=FALSE, message=FALSE}
# Reset R's brain before new analysis session started. It will erase all the objects stored in 
# R memory, while keep loaded libraries.
rm(list = ls())

# Load required packages
library(tidyverse)
library(rgee)
library(sf)
library(geojsonio)
library(reshape2)
library(spectralR)
```

### Upload and process vector data

Function `prepare.vector.data`  takes shapefile with polygons of different classes of surface (habitats, crops, vegetation, etc.), and retrieves ready-for-sampling sf object. One should specify shapefile name (should be within working directory, using absolute paths were not tested), as well as the name of the field which contains class labels. The function extract geometries of all polygons, and marked them by custom labels ('label') as well as automatically assign integer class ID ('class') for each entry. The last variable is required because Google Earth Engine sampler respects only numerical class ID - don't delete any field!  don't panic: resulting dataframe will be marked according to your custom labels, not hard-to-memorizable numbers.

While preparing a shapefile with custom polygons (e.d., in [QGIS](https://qgis.org/en/site/)), try to follow recommendation:
* if possible, draw polygons in homogeneous landscapes, avoid class mixture;
* keep geometries simple, if possible. Avoid multipolygons, holes inside polygons, etc.
* tiny polygons (same size as satellite imagery resolution or lesser) resulted in stronger "edge effect";
* few big polygons easier to process than a lot of small ones;
* GEE has its own memory limitation, which may result in extended processing time

```{r, eval = FALSE}
# Extract polygons from shapefile and prepare sf object with proper structure
sf_df <- prepare.vector.data(system.file("shapes/test_shapefile.shp", package = "spectralR"), "veget_type")
```

```{r, include=FALSE}
sf_df <- prepare.vector.data("./shapes/test_shapefile.shp", "veget_type")
```

Explore resulting spatial object:
```{r}
head(sf_df)
```

Example above uses internal test shapefile. To use your own file, put all the shapefile into your working directory and use followind syntax:
```{r}
# sf_df <- prepare.vector.data("your-shapefile-within-working-directory-name.shp", "name-of-the-field-with-class-labels")
```

### Obtain pixel values from Sentinel 2A image collection

Function `get.pixel.data` is a heart of `spectralR`. It takes sf polygon object, obtained in the previous step, and retrieves data frame with brightness values for each pixel intersected with polygons, for each optical band of Sentinel-2 sensor, marked according to the label of surface class from the polygons. `get.pixel.data` firstly converts sf object into GEE feature collection, then prepares satellite image for pixel sampling and performs sampling, and finally exports resulting object back into an R dataframe (non-spatial now).

One of the most tricky and issues-causing step of this procedure is convertation beetween R's sf object and GEE's feature collection. `rgee` implements three way to do so:
- through the JSON translator (`getInfo`, default)
- using Google Drive (`getInfo_to_asset`)
- using Google Cloud Storage (`gcs_to_asset`)

First one is the most straightforward and quick, but usable only for small data (less than 15000 entries, or 1.5 MB local files). The other two require mediating storage to store your data between convertations (because Earth Engine is Google service and seamlessly integrated with plenty of Google services).

In `spectralR`, we use first two. `get.pixel.data` assesses the size of your either sf object or feature collection, then activates either `getInfo` or `getInfo_to_asset` pathway. If you data is considered being "small", `getInfo` will be used and you will notice nothing special. But, if your data is larger than our arbitrary threshold, the method `getInfo_to_asset` will be activated and you may be prompted to authorize in Google Drive and allow `rgee` to access GDrive files and folders. In such a case, please follow instructions in the R console and then in your web-browser. You may do it once you perform your first large query, - you credits will be stored into your local earthengine environment.

After authorization and first use, folder *rgee_backup* will be created into your Google Drive storage, when all the intermediate files will be stored. Though `get.pixel.data` re-write objects each time it will be launched, we strongly recommend to clean *rgee_backup* folder in your Drive manually time-to-time. Apparently, if you run out of storage, `get.pixel.data` won't be able to use your Google Drive as mediating storage and you will receive an error.


To use `get.pixel.data`, we need to specify some values:

* polygons of surface classes as a sf object, prepared on previous step;

* starting day for Sentinel image collection, as "YYYY-MM-DD". See Note 1 below;

* final day for Sentinel image collection, as "YYYY-MM-DD";

* cloud threshold (maximum per cent of cloud-covered pixels per image) by which individual 
satellite imageries will be filtered;

* scale of resulting satellite images in meters (pixel size). See Note 2 below;

Resulting pixel data will be saved within working directory and can be loaded during
next sessions.

**Note 1**. Particular satellite imagery is typically not ready for instant sampling - it contains clouds, cloud shadows, aerosols, as well as may cover not all the territory you of your interest. Another issue is that each particular pixel slightly differs in reflectance between images taken in different days due to difference in atmospheric conditions and angle of sunlight at the moments images were taken. Google Earth Engine has its own build-in algorithms for image pre-processing, atmospheric corrections and mosaicing, which allows to obtain a ready-to-use, rectified image. Approach used in this script is that to find a median value for each pixel between several images within each of 10 optical band, and thereby make a composite image. To define a set of imageries between which we are going to calculate median, 
we should set a timespan of image collection. Sentinel-2 apparatus takes picture once a 5 days, so if you set up month-long timesnap, you can expect that each pixel value will be calculated based on 5 to 6 values (remember, some images might appear unsatisfactory cloudy).

**Note 2**. Finest resolution for Sentinel data - 10 m, while using larger scale values decreases required computational resources and size of resulting dataframe. Although sampling satellite data performs in a cloud, there are some limitations for geocalculations placed by GEE itself. If you are about to sample large areas, consider setting higher 'scale' value (100, 1000). Read more in GEE [best practices](https://developers.google.com/earth-engine/guides/best_practices).

```{r, collapse = TRUE, eval = FALSE}
# Get pixel data
reflectance = get.pixel.data(sf_df, "2019-05-15", "2019-06-30", 10, 100)

# Save pixel data for further sessions
save(reflectance, file = "reflectance_test_data")
```

Here we choose 100 m scale (pixel size for resulting imagery is 100x100 m), which resulted in sampling dataset of 2060 rows. Finer pixel size would result in a larger sampling dataset, which would require using moderating storage (see use case 2).  

```{r, echo = FALSE}
load(file = "./reflectance_test_data") # restore previously saved pixel data
```

Let's have a look at the resulting data:
```{r}
head(reflectance)
```

We have a dataframe which number of rows equal to the number of sampled "pixels" of satellite image, as well as 10 variables with reflectance values for each of optical band of Sentinel 2. Each sampled pixel has a label of surface class of user's polygon it intersected.

### Visualize results

First of all, one should explore the quality and comprehensiveness of obtained pixel data.
```{r}
load(file = "./reflectance_test_data") # restore previously saved pixel data

summary(factor(reflectance$label)) # how many pixels in each class? 
```

For reliable results, it is recommended to keep similar size of each surface class. Classes which represented by few sampled pixels, should be excluded from the further analysis.

Visual overview of pixel data
```{r, fig.align='center', fig.width=7, fig.height=5}
# Number of spectral values for different classes
ggplot(reflectance, aes(x=label))+
  geom_bar()+
  labs(x = 'Classes of surface', y = 'Number of pixels',
       title = "Total pixel data for different classes of surface",
       caption = 'Data: Sentinel-2 Level-2A')+
  theme_minimal()
```

Function `spectral.reflectance.curve` transform the data and plot smoother curves for each surface class, using `ggplot2`'s `geom_smooth()` aesthetics. For large (thousands of rows) data (and we need large data for reliable conclusions!), `ggplot2` uses *GAM* method for drawing a trendline.

Depending on the data size, it may take some time to process.
```{r, fig.align='center', fig.width=7, fig.height=5}
# Make a ggplot object
p1 <- spectral.curves.plot(reflectance)

# Default plot
p1
```

Since the output of `spectral.curves.plot` is `ggplot` object, we can apply any tools provided by `ggplot2` package to make it more visually pleasant.
```{r, fig.align='center', fig.width=7, fig.height=5}
# Customized plot
p1+
  labs(x = 'Wavelength, nm', y = 'Reflectance',
       colour = "Surface classes",
       fill = "Surface classes",
       title = "Spectral reflectance curves for different classes of surface",
       caption = 'Data: Sentinel-2 Level-2A')+
  theme_minimal()
```

You can save the plot as a *.png (or other common graphical formats) file using `ggsave` or `png()` functions
```{r}
ggsave("Spectral_curves_usecase1.png", width=16, height=12, unit="cm", dpi=300)
```


Function `stat.summary.plot` make a plot with statistical summary of reflectance values (mean, mean-standard deviation, mean+standard deviation) for defined classes of surface. Giving as input reflectance data, the function returns ggplot2 object with basic visual aesthetics. Default aesthetics are line with statistical summary for each satellite band ([geom_line](https://ggplot2.tidyverse.org/reference/geom_linerange.html) + [geom_pointrange](https://ggplot2.tidyverse.org/reference/geom_path.html)).

Wavelengths values (nm) acquired from mean known value for each optical band of [Sentinel 2](https://en.wikipedia.org/wiki/Sentinel-2) sensor.

```{r, fig.align='center', fig.width=7, fig.height=5}
# Make a ggplot object
p2 <- stat.summary.plot(reflectance)

# Default plot
p2
```

Add a touch of customization and save as a picture.
```{r, , fig.align='center', fig.width=7, fig.height=5}
# Customized plot
p2 + 
  labs(x = 'Sentinel-2 bands', y = 'Reflectance',
       colour = "Surface classes",
       title = "Reflectance for different surface classes",
       caption='Data: Sentinel-2 Level-2A\nmean ± standard deviation')+
  theme_minimal()
```

Save the plot as a *.png file
```{r}
ggsave("Statsummary_usecase1.png", width=16, height=12, unit="cm", dpi=300)
```

Function `violin.plot` helps to visualize a reflectance as violin plots for each surface class per satellite bands. It gets reflectance data as input and return ggplot2 object with basic visual aesthetics. Default aesthetics is [geom_violin](https://ggplot2.tidyverse.org/reference/geom_violin.html).

```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', fig.width=7, fig.height=5}
# Make a ggplot object
p3 <- violin.plot(reflectance)

# Customized plot
p3 + 
  labs(x='Surface class',y='Reflectance',
       fill="Surface classes",
       title = "Reflectance for different surface classes",
       caption='Data: Sentinel-2 Level-2A')+
  theme_minimal()

# Save the plot as a *.png file
ggsave("Violins_usecase1.png", width=22, height=16, unit="cm", dpi=300)
```

## Use case 2. Habitats of Buzky Gard National Park, Mykolaiv region, Ukraine.

Environment preparation
```{r, error=FALSE, warning=FALSE, message=FALSE}
# Reset R's brain before new analysis session started. It will erase all the objects stored in 
# R memory, while keep loaded libraries.
rm(list = ls())

# Load required packages
library(tidyverse)
library(rgee)
library(sf)
library(geojsonio)
library(reshape2)
library(spectralR)
```

Upload and process vector data
```{r, eval = FALSE}
# Extract polygons from shapefile and prepare sf object with proper structure
sf_df <- prepare.vector.data(system.file("shapes/SouthernBuh-habitats_shapefile.shp", package = "spectralR"), "eunis_2020")
```

```{r, include=FALSE}
sf_df <- prepare.vector.data("./shapes/SouthernBuh-habitats_shapefile.shp", "eunis_2020")
```

Explore resulting spatial object:
```{r}
head(sf_df)
```

Get reflectance values
```{r, eval = FALSE}
reflectance = get.pixel.data(sf_df, "2019-05-15", "2019-06-30", 10, 10)

# save pixel data for further sessions
save(reflectance, file = "reflectance_BG_data") 
```

Quantitative overview of pixel data
```{r}
load(file = "./reflectance_BG_data") # restore previously saved pixel data

summary(factor(reflectance$label)) # how many pixels in each class?
```

Spectral reflectance curves for different habitat types
```{r, fig.align='center', fig.width=7, fig.height=5}
# Create basic ggplot object
p1 <- spectral.curves.plot(reflectance)

# Plotting
p1+
  labs(x = 'Wavelength, nm', y = 'Reflectance',
       colour = "Habitat types",
       fill = "Habitat types",
       title = "Spectral reflectance curves for different habitat types\nSouthern Buh National park, Ukraine",
       caption = 'Data: Sentinel-2 Level-2A')+
  theme_minimal()
```

Statistical summary for each habitat type
```{r, fig.align='center', fig.width=7, fig.height=5}
# Create basic ggplot object
p2 <- stat.summary.plot(reflectance)

# Plotting
p2 + 
  labs(x = 'Sentinel-2 bands', y = 'Reflectance',
       colour = "Habitat types",
       title = "Reflectance for different habitat types\nSouthern Buh National park, Ukraine",
       caption='Data: Sentinel-2 Level-2A\nmean ± standard deviation')+
  theme_minimal()
```

Create violin plots for given habitat types
```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', fig.width=7, fig.height=5}
# Create basic ggplot object
p3 <- violin.plot(reflectance)

# Plotting
p3 + 
  labs(x='Habitat type', y='Reflectance',
       fill="Habitat types",
       title = "Reflectance for different habitat types\nSouthern Buh National park, Ukraine",
       caption='Data: Sentinel-2 Level-2A')+
  theme_minimal()
```

You also can save and/or transform resulting ggplot objects as you wish, using `ggplot2` and `tidyverse` syntax.
